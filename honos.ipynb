{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0881c944-4aed-4da2-8e21-72412033c1ee",
   "metadata": {},
   "source": [
    "# NER using GPT-3.5\n",
    "\n",
    "### Project name: Honos\n",
    "Date: 24th May 2024\n",
    "\n",
    "Author: Milindi Kodikara | Supervisor: Professor Karin Verspoor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0337bbac-21c4-45c9-b0ca-922bfbc97b72",
   "metadata": {},
   "source": [
    "\n",
    "Before running this notebook:\n",
    "1. [Install Jupyter notebook](https://jupyter.org/install) \n",
    "\n",
    "\n",
    "2. [Setting up Azure OpenAI model](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/working-with-models?tabs=powershell#model-updates)\n",
    "\n",
    "\n",
    "3. [Setting up connection to GPT-3.5 using Azure OpenAI service](https://learn.microsoft.com/en-us/azure/ai-services/openai/quickstart?tabs=command-line%2Cpython-new&pivots=programming-language-python)\n",
    "        - In the Environment variables section, instead of doing what is outlined in the link, add the `API_KEY`, `API-VERSION`, `ENDPOINT` and `DEPLOYMENT-NAME` into a `.env` file in the root folder.\n",
    "        \n",
    "4. Add the correct filename paths for `data` in Step 1 and gold annotated data filename for the `evaluate()` function in Step 4. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f739ac-16fa-4a1b-9855-e8b89fdeb194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d926f35-0054-4d89-bfda-b3d3d589dcc5",
   "metadata": {},
   "source": [
    "\n",
    "### Step 1: Load and pre-process data and prompt library "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a7d5cb-7d77-449d-a3f1-bcfb1281883d",
   "metadata": {},
   "source": [
    "\n",
    "#### Step 1.1: Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc0a4e4-b5b7-441f-b99f-29e18f7ed302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_text.tsv\n",
    "# pmid\\tfilename\\ttext\n",
    "\n",
    "# TODO: Replace filepath for related data file\n",
    "original_data = pd.read_csv(\"../data/ner/genovardis_train_dev_test/dev_text.tsv\", sep='\\t', header=0)\n",
    "\n",
    "# this type will be appended to the final result file\n",
    "data_type = 'dev'\n",
    "\n",
    "# If output needed in the BRAT format\n",
    "generate_brat_format = True\n",
    "\n",
    "# gold ann file to be bratified\n",
    "gold_annotation_filepath = '../data/ner/genovardis_train_dev_test/dev_annotation.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "original_data.head(5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "25ca92b2075915ca",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "len(original_data)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c170e2b03454265",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# TODO: remove this after testing\n",
    "# original_data = original_data.head(2)\n",
    "# \n",
    "# original_data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be60d3202a45483d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# original data has the pmid instances in the text\n",
    "data = original_data.copy(deep=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e0c0a8b4ea22dfc9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "original_data.sample()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1430a879bcdba3ec",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# clean up text by removing the appended pmid and title abstract tags at the start of each section\n",
    "\n",
    "pattern = '(?:[\\d]{1,10}\\|t\\|)(?P<title>[\\w\\W]+)(?:\\\\n[\\d]{1,20}\\|a\\|)(?P<abstract>[\\w\\W]+)'\n",
    "\n",
    "def clean_text(text):\n",
    "    matches = re.search(pattern, text)\n",
    "    reformatted_text = f'{matches.group(\"title\")}\\n{matches.group(\"abstract\")}'\n",
    "    return reformatted_text\n",
    "\n",
    "data['text'] = [clean_text(text) for text in data['text']]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d96ff234e2653dd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data.sample()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db9931374105502c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "len(data)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6296d4e5d31985f9",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "#### Step 1.2: Load prompt library\n",
    "\n",
    "Prompt id structure:\n",
    "`p_<index>_<task>_<language>_<output>`\n",
    "\n",
    "TODO: Figure out `<guideline>_<paradigm>`"
   ],
   "metadata": {},
   "id": "da74db47-221a-40f1-9e02-2fd68220b367"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "prompt_library = pd.read_json('prompts.json')\n",
    "\n",
    "prompt_library"
   ],
   "metadata": {},
   "id": "fb1d18f8-110f-4981-bc3a-40c417cb490a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# TODO: remove this after testing\n",
    "# prompt_library = prompt_library.head(1)\n",
    "# \n",
    "# prompt_library"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f999fda207f1d6d",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "#### Step 1.3: Create data+prompt dataset"
   ],
   "metadata": {},
   "id": "7e17606d-7a57-4044-94b3-ef4b802af0f4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# TODO: Buff up the prompts with guidelines and examples (shots)\n",
    "# pmid prompt_id embedded_prompt\n",
    "def embed_data_in_prompts(row_data):\n",
    "    prompts = []\n",
    "    pmid = row_data['pmid']\n",
    "    data_text = row_data['text']\n",
    "    \n",
    "    for index, row_prompt in prompt_library.iterrows():\n",
    "        instruction = row_prompt['instruction']\n",
    "        prompt_text = row_prompt['text'].format(data_text)\n",
    "        # TODO: Figure out the new line characters \n",
    "        concatenated_prompt = '{}\\n\"{}\"'.format(instruction, prompt_text)\n",
    "        \n",
    "        prompt = {'prompt_id': row_prompt['prompt_id'], 'prompt': concatenated_prompt}\n",
    "        prompts.append(prompt)\n",
    "    \n",
    "    return {'pmid': pmid, 'prompts': prompts}\n"
   ],
   "metadata": {},
   "id": "6dc0bb8a-f112-432c-aee1-335dbf175970",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "embedded_prompt_data_list = [embed_data_in_prompts(row_data) for index, row_data in data.iterrows()]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e3fd79116cffa1c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "embedded_prompt_data_list[0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5905c131cf4c8e7b",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "eac6e4d1-bfb4-4c90-8b7b-d0ffc71d6313",
   "metadata": {},
   "source": [
    "\n",
    "### Step 2: Setting up GPT-3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bac339d-8467-4651-bc3f-72faa835033b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.environ[\"API-KEY\"],  \n",
    "    api_version=os.environ[\"API-VERSION\"],\n",
    "    azure_endpoint=os.environ[\"ENDPOINT\"]\n",
    "    )\n",
    "    \n",
    "deployment_name=os.environ[\"DEPLOYMENT-NAME\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Testing the connection\n",
    "test_response = client.chat.completions.create(model=deployment_name, messages=[{\"role\": \"user\", \"content\": \"Hello, World!\"}])\n",
    "print(test_response.choices[0].message.content)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "efd39ba90dcb4d0b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# TODO: Ask Karin whether we should run again and again to see what gpt generates - yes! later!\n",
    "results_list = []\n",
    "def generate_results(prompt_items):\n",
    "    \n",
    "    pmid = prompt_items['pmid']\n",
    "    \n",
    "    for prompt_item in prompt_items['prompts']:\n",
    "    \n",
    "        prompt_id = prompt_item['prompt_id']\n",
    "        prompt = prompt_item['prompt']\n",
    "        \n",
    "        # TODO: Look into hyper params like temp \n",
    "        response = client.chat.completions.create(model=deployment_name, messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "        \n",
    "        response_result = response.choices[0].message.content\n",
    "        \n",
    "        results_list.append({'pmid': pmid, 'prompt_id': prompt_id, 'result': response_result})\n",
    "    \n",
    "        # print(f'Prompt:\\n{prompt}\\n\\nResponse:\\n{response_result} \\n----------\\n')\n",
    "        print(f'Prompt_id:\\n{prompt_id}\\n\\npmid:\\n{pmid}\\n----------\\n')\n",
    "    \n",
    "    return results_list\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b71f8c1697ad95c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt_id:\n",
      "p_001_ner_en_tsv\n",
      "\n",
      "pmid:\n",
      "24677153\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[60], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m embedded_prompt_data \u001B[38;5;129;01min\u001B[39;00m embedded_prompt_data_list:\n\u001B[0;32m----> 2\u001B[0m     generate_results(embedded_prompt_data)\n",
      "Cell \u001B[0;32mIn[59], line 13\u001B[0m, in \u001B[0;36mgenerate_results\u001B[0;34m(prompt_items)\u001B[0m\n\u001B[1;32m     10\u001B[0m prompt \u001B[38;5;241m=\u001B[39m prompt_item[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprompt\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m# TODO: Look into hyper params like temp \u001B[39;00m\n\u001B[0;32m---> 13\u001B[0m response \u001B[38;5;241m=\u001B[39m client\u001B[38;5;241m.\u001B[39mchat\u001B[38;5;241m.\u001B[39mcompletions\u001B[38;5;241m.\u001B[39mcreate(model\u001B[38;5;241m=\u001B[39mdeployment_name, messages\u001B[38;5;241m=\u001B[39m[{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrole\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muser\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m\"\u001B[39m: prompt}])\n\u001B[1;32m     15\u001B[0m response_result \u001B[38;5;241m=\u001B[39m response\u001B[38;5;241m.\u001B[39mchoices[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mmessage\u001B[38;5;241m.\u001B[39mcontent\n\u001B[1;32m     17\u001B[0m results_list\u001B[38;5;241m.\u001B[39mappend({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpmid\u001B[39m\u001B[38;5;124m'\u001B[39m: pmid, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprompt_id\u001B[39m\u001B[38;5;124m'\u001B[39m: prompt_id, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mresult\u001B[39m\u001B[38;5;124m'\u001B[39m: response_result})\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/openai/_utils/_utils.py:277\u001B[0m, in \u001B[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    275\u001B[0m             msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMissing required argument: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquote(missing[\u001B[38;5;241m0\u001B[39m])\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    276\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(msg)\n\u001B[0;32m--> 277\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/openai/resources/chat/completions.py:590\u001B[0m, in \u001B[0;36mCompletions.create\u001B[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001B[0m\n\u001B[1;32m    558\u001B[0m \u001B[38;5;129m@required_args\u001B[39m([\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m], [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m    559\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate\u001B[39m(\n\u001B[1;32m    560\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    588\u001B[0m     timeout: \u001B[38;5;28mfloat\u001B[39m \u001B[38;5;241m|\u001B[39m httpx\u001B[38;5;241m.\u001B[39mTimeout \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m|\u001B[39m NotGiven \u001B[38;5;241m=\u001B[39m NOT_GIVEN,\n\u001B[1;32m    589\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ChatCompletion \u001B[38;5;241m|\u001B[39m Stream[ChatCompletionChunk]:\n\u001B[0;32m--> 590\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_post(\n\u001B[1;32m    591\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/chat/completions\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    592\u001B[0m         body\u001B[38;5;241m=\u001B[39mmaybe_transform(\n\u001B[1;32m    593\u001B[0m             {\n\u001B[1;32m    594\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m: messages,\n\u001B[1;32m    595\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m: model,\n\u001B[1;32m    596\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfrequency_penalty\u001B[39m\u001B[38;5;124m\"\u001B[39m: frequency_penalty,\n\u001B[1;32m    597\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfunction_call\u001B[39m\u001B[38;5;124m\"\u001B[39m: function_call,\n\u001B[1;32m    598\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfunctions\u001B[39m\u001B[38;5;124m\"\u001B[39m: functions,\n\u001B[1;32m    599\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlogit_bias\u001B[39m\u001B[38;5;124m\"\u001B[39m: logit_bias,\n\u001B[1;32m    600\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlogprobs\u001B[39m\u001B[38;5;124m\"\u001B[39m: logprobs,\n\u001B[1;32m    601\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax_tokens\u001B[39m\u001B[38;5;124m\"\u001B[39m: max_tokens,\n\u001B[1;32m    602\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mn\u001B[39m\u001B[38;5;124m\"\u001B[39m: n,\n\u001B[1;32m    603\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpresence_penalty\u001B[39m\u001B[38;5;124m\"\u001B[39m: presence_penalty,\n\u001B[1;32m    604\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresponse_format\u001B[39m\u001B[38;5;124m\"\u001B[39m: response_format,\n\u001B[1;32m    605\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mseed\u001B[39m\u001B[38;5;124m\"\u001B[39m: seed,\n\u001B[1;32m    606\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstop\u001B[39m\u001B[38;5;124m\"\u001B[39m: stop,\n\u001B[1;32m    607\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m: stream,\n\u001B[1;32m    608\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream_options\u001B[39m\u001B[38;5;124m\"\u001B[39m: stream_options,\n\u001B[1;32m    609\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtemperature\u001B[39m\u001B[38;5;124m\"\u001B[39m: temperature,\n\u001B[1;32m    610\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtool_choice\u001B[39m\u001B[38;5;124m\"\u001B[39m: tool_choice,\n\u001B[1;32m    611\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtools\u001B[39m\u001B[38;5;124m\"\u001B[39m: tools,\n\u001B[1;32m    612\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtop_logprobs\u001B[39m\u001B[38;5;124m\"\u001B[39m: top_logprobs,\n\u001B[1;32m    613\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtop_p\u001B[39m\u001B[38;5;124m\"\u001B[39m: top_p,\n\u001B[1;32m    614\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muser\u001B[39m\u001B[38;5;124m\"\u001B[39m: user,\n\u001B[1;32m    615\u001B[0m             },\n\u001B[1;32m    616\u001B[0m             completion_create_params\u001B[38;5;241m.\u001B[39mCompletionCreateParams,\n\u001B[1;32m    617\u001B[0m         ),\n\u001B[1;32m    618\u001B[0m         options\u001B[38;5;241m=\u001B[39mmake_request_options(\n\u001B[1;32m    619\u001B[0m             extra_headers\u001B[38;5;241m=\u001B[39mextra_headers, extra_query\u001B[38;5;241m=\u001B[39mextra_query, extra_body\u001B[38;5;241m=\u001B[39mextra_body, timeout\u001B[38;5;241m=\u001B[39mtimeout\n\u001B[1;32m    620\u001B[0m         ),\n\u001B[1;32m    621\u001B[0m         cast_to\u001B[38;5;241m=\u001B[39mChatCompletion,\n\u001B[1;32m    622\u001B[0m         stream\u001B[38;5;241m=\u001B[39mstream \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    623\u001B[0m         stream_cls\u001B[38;5;241m=\u001B[39mStream[ChatCompletionChunk],\n\u001B[1;32m    624\u001B[0m     )\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/openai/_base_client.py:1240\u001B[0m, in \u001B[0;36mSyncAPIClient.post\u001B[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1226\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpost\u001B[39m(\n\u001B[1;32m   1227\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1228\u001B[0m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1235\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1236\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[1;32m   1237\u001B[0m     opts \u001B[38;5;241m=\u001B[39m FinalRequestOptions\u001B[38;5;241m.\u001B[39mconstruct(\n\u001B[1;32m   1238\u001B[0m         method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpost\u001B[39m\u001B[38;5;124m\"\u001B[39m, url\u001B[38;5;241m=\u001B[39mpath, json_data\u001B[38;5;241m=\u001B[39mbody, files\u001B[38;5;241m=\u001B[39mto_httpx_files(files), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions\n\u001B[1;32m   1239\u001B[0m     )\n\u001B[0;32m-> 1240\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrequest(cast_to, opts, stream\u001B[38;5;241m=\u001B[39mstream, stream_cls\u001B[38;5;241m=\u001B[39mstream_cls))\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/openai/_base_client.py:921\u001B[0m, in \u001B[0;36mSyncAPIClient.request\u001B[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[1;32m    912\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrequest\u001B[39m(\n\u001B[1;32m    913\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    914\u001B[0m     cast_to: Type[ResponseT],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    919\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    920\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[0;32m--> 921\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_request(\n\u001B[1;32m    922\u001B[0m         cast_to\u001B[38;5;241m=\u001B[39mcast_to,\n\u001B[1;32m    923\u001B[0m         options\u001B[38;5;241m=\u001B[39moptions,\n\u001B[1;32m    924\u001B[0m         stream\u001B[38;5;241m=\u001B[39mstream,\n\u001B[1;32m    925\u001B[0m         stream_cls\u001B[38;5;241m=\u001B[39mstream_cls,\n\u001B[1;32m    926\u001B[0m         remaining_retries\u001B[38;5;241m=\u001B[39mremaining_retries,\n\u001B[1;32m    927\u001B[0m     )\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/openai/_base_client.py:952\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[1;32m    949\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSending HTTP Request: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, request\u001B[38;5;241m.\u001B[39mmethod, request\u001B[38;5;241m.\u001B[39murl)\n\u001B[1;32m    951\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 952\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_client\u001B[38;5;241m.\u001B[39msend(\n\u001B[1;32m    953\u001B[0m         request,\n\u001B[1;32m    954\u001B[0m         stream\u001B[38;5;241m=\u001B[39mstream \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_stream_response_body(request\u001B[38;5;241m=\u001B[39mrequest),\n\u001B[1;32m    955\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m    956\u001B[0m     )\n\u001B[1;32m    957\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m httpx\u001B[38;5;241m.\u001B[39mTimeoutException \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m    958\u001B[0m     log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEncountered httpx.TimeoutException\u001B[39m\u001B[38;5;124m\"\u001B[39m, exc_info\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/httpx/_client.py:914\u001B[0m, in \u001B[0;36mClient.send\u001B[0;34m(self, request, stream, auth, follow_redirects)\u001B[0m\n\u001B[1;32m    906\u001B[0m follow_redirects \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    907\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfollow_redirects\n\u001B[1;32m    908\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(follow_redirects, UseClientDefault)\n\u001B[1;32m    909\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m follow_redirects\n\u001B[1;32m    910\u001B[0m )\n\u001B[1;32m    912\u001B[0m auth \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_request_auth(request, auth)\n\u001B[0;32m--> 914\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_send_handling_auth(\n\u001B[1;32m    915\u001B[0m     request,\n\u001B[1;32m    916\u001B[0m     auth\u001B[38;5;241m=\u001B[39mauth,\n\u001B[1;32m    917\u001B[0m     follow_redirects\u001B[38;5;241m=\u001B[39mfollow_redirects,\n\u001B[1;32m    918\u001B[0m     history\u001B[38;5;241m=\u001B[39m[],\n\u001B[1;32m    919\u001B[0m )\n\u001B[1;32m    920\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    921\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m stream:\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/httpx/_client.py:942\u001B[0m, in \u001B[0;36mClient._send_handling_auth\u001B[0;34m(self, request, auth, follow_redirects, history)\u001B[0m\n\u001B[1;32m    939\u001B[0m request \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(auth_flow)\n\u001B[1;32m    941\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 942\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_send_handling_redirects(\n\u001B[1;32m    943\u001B[0m         request,\n\u001B[1;32m    944\u001B[0m         follow_redirects\u001B[38;5;241m=\u001B[39mfollow_redirects,\n\u001B[1;32m    945\u001B[0m         history\u001B[38;5;241m=\u001B[39mhistory,\n\u001B[1;32m    946\u001B[0m     )\n\u001B[1;32m    947\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    948\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/httpx/_client.py:979\u001B[0m, in \u001B[0;36mClient._send_handling_redirects\u001B[0;34m(self, request, follow_redirects, history)\u001B[0m\n\u001B[1;32m    976\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_event_hooks[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrequest\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[1;32m    977\u001B[0m     hook(request)\n\u001B[0;32m--> 979\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_send_single_request(request)\n\u001B[1;32m    980\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    981\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_event_hooks[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresponse\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/httpx/_client.py:1015\u001B[0m, in \u001B[0;36mClient._send_single_request\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m   1010\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m   1011\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAttempted to send an async request with a sync Client instance.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1012\u001B[0m     )\n\u001B[1;32m   1014\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m request_context(request\u001B[38;5;241m=\u001B[39mrequest):\n\u001B[0;32m-> 1015\u001B[0m     response \u001B[38;5;241m=\u001B[39m transport\u001B[38;5;241m.\u001B[39mhandle_request(request)\n\u001B[1;32m   1017\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response\u001B[38;5;241m.\u001B[39mstream, SyncByteStream)\n\u001B[1;32m   1019\u001B[0m response\u001B[38;5;241m.\u001B[39mrequest \u001B[38;5;241m=\u001B[39m request\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/httpx/_transports/default.py:233\u001B[0m, in \u001B[0;36mHTTPTransport.handle_request\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m    220\u001B[0m req \u001B[38;5;241m=\u001B[39m httpcore\u001B[38;5;241m.\u001B[39mRequest(\n\u001B[1;32m    221\u001B[0m     method\u001B[38;5;241m=\u001B[39mrequest\u001B[38;5;241m.\u001B[39mmethod,\n\u001B[1;32m    222\u001B[0m     url\u001B[38;5;241m=\u001B[39mhttpcore\u001B[38;5;241m.\u001B[39mURL(\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    230\u001B[0m     extensions\u001B[38;5;241m=\u001B[39mrequest\u001B[38;5;241m.\u001B[39mextensions,\n\u001B[1;32m    231\u001B[0m )\n\u001B[1;32m    232\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m map_httpcore_exceptions():\n\u001B[0;32m--> 233\u001B[0m     resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pool\u001B[38;5;241m.\u001B[39mhandle_request(req)\n\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(resp\u001B[38;5;241m.\u001B[39mstream, typing\u001B[38;5;241m.\u001B[39mIterable)\n\u001B[1;32m    237\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m Response(\n\u001B[1;32m    238\u001B[0m     status_code\u001B[38;5;241m=\u001B[39mresp\u001B[38;5;241m.\u001B[39mstatus,\n\u001B[1;32m    239\u001B[0m     headers\u001B[38;5;241m=\u001B[39mresp\u001B[38;5;241m.\u001B[39mheaders,\n\u001B[1;32m    240\u001B[0m     stream\u001B[38;5;241m=\u001B[39mResponseStream(resp\u001B[38;5;241m.\u001B[39mstream),\n\u001B[1;32m    241\u001B[0m     extensions\u001B[38;5;241m=\u001B[39mresp\u001B[38;5;241m.\u001B[39mextensions,\n\u001B[1;32m    242\u001B[0m )\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:216\u001B[0m, in \u001B[0;36mConnectionPool.handle_request\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m    213\u001B[0m         closing \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_assign_requests_to_connections()\n\u001B[1;32m    215\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_close_connections(closing)\n\u001B[0;32m--> 216\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m exc \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    218\u001B[0m \u001B[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001B[39;00m\n\u001B[1;32m    219\u001B[0m \u001B[38;5;66;03m# the point at which the response is closed.\u001B[39;00m\n\u001B[1;32m    220\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response\u001B[38;5;241m.\u001B[39mstream, Iterable)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:196\u001B[0m, in \u001B[0;36mConnectionPool.handle_request\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m    192\u001B[0m connection \u001B[38;5;241m=\u001B[39m pool_request\u001B[38;5;241m.\u001B[39mwait_for_connection(timeout\u001B[38;5;241m=\u001B[39mtimeout)\n\u001B[1;32m    194\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    195\u001B[0m     \u001B[38;5;66;03m# Send the request on the assigned connection.\u001B[39;00m\n\u001B[0;32m--> 196\u001B[0m     response \u001B[38;5;241m=\u001B[39m connection\u001B[38;5;241m.\u001B[39mhandle_request(\n\u001B[1;32m    197\u001B[0m         pool_request\u001B[38;5;241m.\u001B[39mrequest\n\u001B[1;32m    198\u001B[0m     )\n\u001B[1;32m    199\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ConnectionNotAvailable:\n\u001B[1;32m    200\u001B[0m     \u001B[38;5;66;03m# In some cases a connection may initially be available to\u001B[39;00m\n\u001B[1;32m    201\u001B[0m     \u001B[38;5;66;03m# handle a request, but then become unavailable.\u001B[39;00m\n\u001B[1;32m    202\u001B[0m     \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m    203\u001B[0m     \u001B[38;5;66;03m# In this case we clear the connection and try again.\u001B[39;00m\n\u001B[1;32m    204\u001B[0m     pool_request\u001B[38;5;241m.\u001B[39mclear_connection()\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/httpcore/_sync/connection.py:101\u001B[0m, in \u001B[0;36mHTTPConnection.handle_request\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m     98\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_connect_failed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m     99\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m exc\n\u001B[0;32m--> 101\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_connection\u001B[38;5;241m.\u001B[39mhandle_request(request)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/httpcore/_sync/http11.py:143\u001B[0m, in \u001B[0;36mHTTP11Connection.handle_request\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m    141\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m Trace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresponse_closed\u001B[39m\u001B[38;5;124m\"\u001B[39m, logger, request) \u001B[38;5;28;01mas\u001B[39;00m trace:\n\u001B[1;32m    142\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_response_closed()\n\u001B[0;32m--> 143\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exc\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/httpcore/_sync/http11.py:113\u001B[0m, in \u001B[0;36mHTTP11Connection.handle_request\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m    102\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m    104\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m Trace(\n\u001B[1;32m    105\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreceive_response_headers\u001B[39m\u001B[38;5;124m\"\u001B[39m, logger, request, kwargs\n\u001B[1;32m    106\u001B[0m ) \u001B[38;5;28;01mas\u001B[39;00m trace:\n\u001B[1;32m    107\u001B[0m     (\n\u001B[1;32m    108\u001B[0m         http_version,\n\u001B[1;32m    109\u001B[0m         status,\n\u001B[1;32m    110\u001B[0m         reason_phrase,\n\u001B[1;32m    111\u001B[0m         headers,\n\u001B[1;32m    112\u001B[0m         trailing_data,\n\u001B[0;32m--> 113\u001B[0m     ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_receive_response_headers(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    114\u001B[0m     trace\u001B[38;5;241m.\u001B[39mreturn_value \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    115\u001B[0m         http_version,\n\u001B[1;32m    116\u001B[0m         status,\n\u001B[1;32m    117\u001B[0m         reason_phrase,\n\u001B[1;32m    118\u001B[0m         headers,\n\u001B[1;32m    119\u001B[0m     )\n\u001B[1;32m    121\u001B[0m network_stream \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_network_stream\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/httpcore/_sync/http11.py:186\u001B[0m, in \u001B[0;36mHTTP11Connection._receive_response_headers\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m    183\u001B[0m timeout \u001B[38;5;241m=\u001B[39m timeouts\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mread\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m    185\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 186\u001B[0m     event \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_receive_event(timeout\u001B[38;5;241m=\u001B[39mtimeout)\n\u001B[1;32m    187\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(event, h11\u001B[38;5;241m.\u001B[39mResponse):\n\u001B[1;32m    188\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/httpcore/_sync/http11.py:224\u001B[0m, in \u001B[0;36mHTTP11Connection._receive_event\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    221\u001B[0m     event \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_h11_state\u001B[38;5;241m.\u001B[39mnext_event()\n\u001B[1;32m    223\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m event \u001B[38;5;129;01mis\u001B[39;00m h11\u001B[38;5;241m.\u001B[39mNEED_DATA:\n\u001B[0;32m--> 224\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_network_stream\u001B[38;5;241m.\u001B[39mread(\n\u001B[1;32m    225\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mREAD_NUM_BYTES, timeout\u001B[38;5;241m=\u001B[39mtimeout\n\u001B[1;32m    226\u001B[0m     )\n\u001B[1;32m    228\u001B[0m     \u001B[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001B[39;00m\n\u001B[1;32m    229\u001B[0m     \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m    230\u001B[0m     \u001B[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    234\u001B[0m     \u001B[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001B[39;00m\n\u001B[1;32m    235\u001B[0m     \u001B[38;5;66;03m# it as a ConnectError.\u001B[39;00m\n\u001B[1;32m    236\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;241m==\u001B[39m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_h11_state\u001B[38;5;241m.\u001B[39mtheir_state \u001B[38;5;241m==\u001B[39m h11\u001B[38;5;241m.\u001B[39mSEND_RESPONSE:\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/httpcore/_backends/sync.py:126\u001B[0m, in \u001B[0;36mSyncStream.read\u001B[0;34m(self, max_bytes, timeout)\u001B[0m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m map_exceptions(exc_map):\n\u001B[1;32m    125\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sock\u001B[38;5;241m.\u001B[39msettimeout(timeout)\n\u001B[0;32m--> 126\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sock\u001B[38;5;241m.\u001B[39mrecv(max_bytes)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/ssl.py:1296\u001B[0m, in \u001B[0;36mSSLSocket.recv\u001B[0;34m(self, buflen, flags)\u001B[0m\n\u001B[1;32m   1292\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m flags \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1293\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1294\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero flags not allowed in calls to recv() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[1;32m   1295\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m)\n\u001B[0;32m-> 1296\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mread(buflen)\n\u001B[1;32m   1297\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1298\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mrecv(buflen, flags)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/ssl.py:1169\u001B[0m, in \u001B[0;36mSSLSocket.read\u001B[0;34m(self, len, buffer)\u001B[0m\n\u001B[1;32m   1167\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m, buffer)\n\u001B[1;32m   1168\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1169\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m)\n\u001B[1;32m   1170\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m SSLError \u001B[38;5;28;01mas\u001B[39;00m x:\n\u001B[1;32m   1171\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m x\u001B[38;5;241m.\u001B[39margs[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m==\u001B[39m SSL_ERROR_EOF \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msuppress_ragged_eofs:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for embedded_prompt_data in embedded_prompt_data_list:\n",
    "    generate_results(embedded_prompt_data)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ff8b7c3321ce93d",
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "results_list"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac9d89026d543e42",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "len(results_list)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f90944f4d4f74661",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0ce5f688-6a65-4e58-a070-22caf6cdf95d",
   "metadata": {},
   "source": [
    "### Step 3: Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# create df from results list and data df\n",
    "# columns = pmid, prompt_id, filename, label, offset1, offset2, span\n",
    "extracted_entity_results = pd.DataFrame(columns=['pmid','prompt_id','filename','label', 'offset_checked', 'offset1','offset2','span'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81729923a951ac42",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "len(extracted_entity_results)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b445e9eccce4b77",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "label_entity_pattern = '^(?P<label>DNAMutation|SNP|DNAAllele|NucleotideChange|OtherMutation|Gene|Disease)\\s+(?P<span>[\\w\\W]+)$'\n",
    "\n",
    "def extract_tuple(tuple_string):\n",
    "    stripped_tuple_string = tuple_string.strip()\n",
    "    matches = re.search(label_entity_pattern, stripped_tuple_string)\n",
    "    \n",
    "    if not matches:\n",
    "        return\n",
    "    \n",
    "    label = matches.group(\"label\").strip()\n",
    "    span = matches.group(\"span\").strip()\n",
    "    \n",
    "    return {'label': label, 'span': span}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ad88bf60dafa5b0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# extract each entity from the combined result string from gpt-3.5\n",
    "# add each extracted tuple as a new row in extracted_entity_results df\n",
    "def extract_ner_results(pmid, prompt_id, result_string):\n",
    "    extracted_list = result_string.splitlines()\n",
    "    extracted_tuple_list = [ extract_tuple(result_string) for result_string in extracted_list]\n",
    "    \n",
    "    for extracted_tuple in extracted_tuple_list:\n",
    "        if extracted_tuple:\n",
    "            filename = data.loc[data['pmid'] == pmid, 'filename'].iloc[0]\n",
    "            filename_ann = filename.replace('txt', 'ann')\n",
    "            df_row = {\n",
    "                    \"pmid\": pmid,\n",
    "                    \"prompt_id\": prompt_id,\n",
    "                    \"filename\" : filename_ann,\n",
    "                    \"label\": extracted_tuple['label'],\n",
    "                    \"offset_checked\": False,\n",
    "                    \"offset1\": '',\n",
    "                    \"offset2\": '',\n",
    "                    \"span\": extracted_tuple['span']\n",
    "                }\n",
    "        \n",
    "            extracted_entity_results.loc[len(extracted_entity_results)] = df_row\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "986f798aed3ca42b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# extract the concatenated results strings into a new line for each tuple \n",
    "for result_dict in results_list:\n",
    "    extract_ner_results(result_dict['pmid'], result_dict['prompt_id'], result_dict['result'])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba7743f3b0d9c2bd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "extracted_entity_results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4f69ce585b7d7eb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "len(extracted_entity_results)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d976196e5c4e9fea",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Find offsets \n",
    "\n",
    "# loop df, find each span, calculate the word length, find the indexes of each occurance \n",
    "for _, row in extracted_entity_results.iterrows():\n",
    "    pmid = row['pmid']\n",
    "    prompt_id = row['prompt_id']\n",
    "    # find the text from the original_data with the pmid\n",
    "    text = original_data.loc[original_data['pmid'] == pmid, 'text'].iloc[0]\n",
    "    \n",
    "    if not row['offset_checked'] and row['offset1'] == '':\n",
    "        span = row['span']\n",
    "        span_length = len(span)\n",
    "        span_start_indexes = [m.start() for m in re.finditer(re.escape(span), text)]\n",
    "        span_count = 0\n",
    "        \n",
    "        matching_spans = extracted_entity_results[(extracted_entity_results['pmid']==pmid) & (extracted_entity_results['prompt_id']==prompt_id) & (extracted_entity_results['span']==span) & (extracted_entity_results['offset1']=='') & (extracted_entity_results['offset_checked']==False)]\n",
    "        \n",
    "        for index, matched_span in matching_spans.iterrows(): \n",
    "            if span_start_indexes and span_count < len(span_start_indexes):\n",
    "                extracted_entity_results.loc[index, 'offset1'] = str(span_start_indexes[span_count])\n",
    "                extracted_entity_results.loc[index, 'offset2'] = str(span_start_indexes[span_count] + span_length)\n",
    "                \n",
    "                span_count = span_count + 1\n",
    "            else: \n",
    "                # Add -1 to extra or missing ones \n",
    "                extracted_entity_results.loc[index, 'offset1'] = '-1'\n",
    "                extracted_entity_results.loc[index, 'offset2'] = '-1'\n",
    "                \n",
    "            extracted_entity_results.loc[index, 'offset_checked'] = True\n",
    "            \n",
    "        # testing code\n",
    "        # test_matching_spans = extracted_entity_results[(extracted_entity_results['pmid']==pmid) & (extracted_entity_results['prompt_id']==prompt_id) & (extracted_entity_results['span']==span)]\n",
    "        # \n",
    "        # print(test_matching_spans)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c120fe53384d5e53",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "extracted_entity_results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4dda2d6069e63a23",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "len(extracted_entity_results)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b42da2e6058cb0d2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# extract the hallucinations\n",
    "hallucinated_results = extracted_entity_results[(extracted_entity_results['offset1'] == '-1') & (extracted_entity_results['offset2'] == '-1')]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea6419f4290dc017",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# remove hallucinations\n",
    "extracted_entity_results = extracted_entity_results[(extracted_entity_results['offset1'] != '-1') & (extracted_entity_results['offset2'] != '-1')]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe1fc86f056705bf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "extracted_entity_results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2f7ae68b7c12551",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "len(extracted_entity_results)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86edcea9bf90fa98",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Step 4: Evaluation\n",
    "\n",
    "Evaluation log is found in `eval_log.tsv`"
   ],
   "metadata": {},
   "id": "5b2da4d1-bb9b-4b6a-932c-0ceecc811e2b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "evaluation_log_filepath = \"evaluation.tsv\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9be144593924e6c6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if os.path.isfile(evaluation_log_filepath):\n",
    "    eval_log_df=pd.read_csv(evaluation_log_filepath, sep='\\t', header=0)\n",
    "else:\n",
    "    # TODO: Keep track of the variations between the runs eg: hyperparams (fixed), prompt that worked best etc. to add the metrics for result \n",
    "    # TODO: Keep track of the hallucinations like the # of entities found that got chopped off coz they can tbe mapped to the text, confabulate\n",
    "    eval_log_df = pd.DataFrame(columns=['prompt_id', 'data_type', 'true_positive', 'false_positive', 'false_negative', 'precision', 'recall', 'f1', 'hallucination_count', 'date'])\n",
    "\n",
    "def update_eval_log(eval_prompt_id, hallucination_count):\n",
    "    eval_log_df.loc[len(eval_log_df.index)] = [eval_prompt_id, data_type, 0, 0, 0, 0, 0, 0, hallucination_count, datetime.today().strftime('%Y-%m-%d %H:%M:%S')]\n",
    "        "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc89a767005e66f3",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Step 5: Saving output\n",
    "\n",
    "Save output files in the following forms:\n",
    "1. `.tsv` file and `.zip` compressed folder containing the extracted entities in the following format: \n",
    "  `pmid   filename   label   offset1   offset2   span`.\n",
    "2. `.tsv` file containing the gold standard annotations in the following BRAT format: \n",
    "  `mark   label offset1 offset2   span`.\n",
    "3. `.tsv` file containing the extracted entities in the following BRAT format: \n",
    "  `mark   label offset1 offset2   span`.\n",
    "\n"
   ],
   "metadata": {},
   "id": "96d5210a-e7e4-49b5-a29d-9fe8c28a179f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# train_annotations.tsv\n",
    "# pmid\\tfilename\\tmark\\tlabel\\toffset1\\toffset2\\tspan\n",
    "\n",
    "# Read and find what other people have done \n",
    "\n",
    "# brat format for NER\n",
    "# TODO: Ask Karin about the BRAT format correctedness\n",
    "# <unique_id>   <label> <offset1> <offset2>   <span> \n",
    "def save_brat_output(brat, df_to_save=None, filename=\"./results/temp.tsv\"):\n",
    "    \n",
    "    if brat:    \n",
    "        df_to_save[\"label-offsets\"] = df_to_save.apply(\n",
    "        lambda df_row: f\"{df_row['label']} {df_row['offset1']} {df_row['offset2']}\",axis=1)\n",
    "        \n",
    "        if 'mark' not in df_to_save.columns:\n",
    "            df_to_save[\"mark\"] = df_to_save.apply(lambda df_row: f\"T{df_row.name+1}\",axis=1)\n",
    "\n",
    "        formatted_df_to_save = df_to_save.loc[:, ['mark', 'label-offsets', 'span']]\n",
    "        formatted_df_to_save.to_csv(filename, sep ='\\t', index=False, header=False)\n",
    "        \n",
    "        print(f'----BRAT----\\nOriginal data len: {len(df_to_save)}, Reformatted len: {len(formatted_df_to_save)}\\n')\n",
    "        print(f\"Reformatted data:\\n--------------------\\n\\n{formatted_df_to_save.head(5)}\\n--------------------\\n\\n\")\n",
    "        \n",
    "    if not brat:\n",
    "        formatted_df_to_save = df_to_save.loc[:, ['pmid', 'filename', 'label', 'offset1', 'offset2', 'span']]\n",
    "        formatted_df_to_save.to_csv(f\"{filename}.tsv\", sep ='\\t', index=False, header=True)\n",
    "        compression_configs = dict(method='zip',\n",
    "                        archive_name=f'{filename}.tsv')  \n",
    "        formatted_df_to_save.to_csv(f\"{filename}.zip\", sep ='\\t', index=False, header=True, compression=compression_configs)\n",
    "        \n",
    "        print(f'Original data len: {len(df_to_save)}, Reformatted len: {len(formatted_df_to_save)}\\n')\n",
    "        print(f\"Reformatted data:\\n--------------------\\n\\n{formatted_df_to_save.head(5)}\\n--------------------\\n\\n\")\n",
    "    "
   ],
   "metadata": {},
   "id": "4a8ce412-2e29-4838-90a5-15c9a72e4011",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Save gold annotations in BRAT format\n",
    "if gold_annotation_filepath != \"\" and generate_brat_format:\n",
    "    gold_annotations_df = pd.read_csv(gold_annotation_filepath, sep='\\t', header=0)\n",
    "    \n",
    "    gold_annotations_df = gold_annotations_df.drop(['mark'], axis=1)\n",
    "    \n",
    "    for _, prompt in prompt_library.iterrows():\n",
    "        prompt_id = prompt['prompt_id']\n",
    "        gold_annotations_filename = f'results/brateval/gold/{prompt_id}_{data_type}.ann'\n",
    "        save_brat_output(True, gold_annotations_df, gold_annotations_filename)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "12f364e30eacdd45",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for _, prompt in prompt_library.iterrows():\n",
    "    prompt_id = prompt['prompt_id']\n",
    "    results_subset = extracted_entity_results[(extracted_entity_results['prompt_id']==prompt_id)]\n",
    "    \n",
    "    # Save results in BRAT format\n",
    "    if generate_brat_format:\n",
    "        results_brat_filename = f'results/brateval/eval/{prompt_id}_{data_type}.ann'\n",
    "        save_brat_output(True, results_subset, results_brat_filename)\n",
    "        \n",
    "    # Update eval log\n",
    "    hallucination_count = len(hallucinated_results[(hallucinated_results['prompt_id']==prompt_id)])\n",
    "    update_eval_log(prompt_id, hallucination_count)\n",
    "    # Save whole result output\n",
    "    results_filename = f'results/{prompt_id}_{data_type}'\n",
    "    save_brat_output(False, results_subset, results_filename)\n",
    "    "
   ],
   "metadata": {},
   "id": "19a97533-fd35-41cd-801c-ac42721da509",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Save eval_log file\n",
    "\n",
    "# /Users/milindi/Documents/Honours/Projects/honos/results/brateval/gold\n",
    "# /Users/milindi/Documents/Honours/Projects/honos/results/brateval/eval\n",
    "eval_log_df.to_csv('eval_log.tsv', sep ='\\t', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e511cb49c654f939",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "`mvn exec:java -Dexec.mainClass=au.com.nicta.csp.brateval.CompareEntities -Dexec.args=\"-e /Users/milindi/Documents/Honours/Projects/honos/results/brateval/eval -g /Users/milindi/Documents/Honours/Projects/honos/results/brateval/gold -s exact\" -X`"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7828fab82708e95a"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "da22023b1ccf9313"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
